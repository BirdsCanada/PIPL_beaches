---
title: "loadData"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(tidyverse)
library(fuzzyjoin)
```

Note: I'm using relative paths as of right now, my file structure includes a folder with the project subdirectory and a Data folder within, my wd is the project subdirectory
Is this the path style I should keep using?

To Do:
get complete beach area, and parking lot area data
update management blanks


Follow-Up Notes:
-loc_id What is this? is it a coordinates or correlates to a beach?
-Not sure what to do about locations joined in some years but separate in others
-2012-2017 BRC I have all Northern NS survey data raw, but only sandwalkers and dog raw for southern (email someone if needed)


These Beaches are mentioned in spreadsheets but will be excluded since they're not in the BRC or the GIS data and don't appear to be regularly monitored:
"Margaree Harbour", "MacKay's Point", "Port Mouton Island", "Jimtown", "Linwood", "South Lakevale (Cribbons)", "Tracadie Big Island / Delorey", "Tracadie West Arm", "Ratcliffe Hills (The Cape)"


Here I load in the 2017-2021 BRC data that was downloaded from Nature Counts and saved as a .csv
```{r load data}
#function to remove columns that are all NA
all_na <- function(x) any(!is.na(x)) 

#create a function to clean dfs from QGIS
#where dat has a name column in first column (either BeachID or Name)
#must have beachnames vector loaded with the correct 66 spellings
QGIS_names<-function(dat = dat){
  dat[,1]%<>% 
  gsub("Crescent Beach", paste(beachnames[15]), .) %>%
  gsub("Durham Lane",paste(beachnames[20]), .) %>% 
  gsub("Grahams Cove", paste(beachnames[24]), .) %>%
  gsub("Harbour Breeze", paste(beachnames[26]), .) %>%
  gsub("Inverness", paste(beachnames[29]), .) %>% 
  gsub("Gull Island Beach", paste(beachnames[60]), .)
  
  x<-which(dat[,1] == "Port Joli (Goose Haven)") #find all rows with the wrong name
dat[paste(x), 1]<-"Goose Haven" #replace with correct name beachnames[64]
return(dat)
}

#path goes back a level to enter Data folder and access csv

#survey data for all sites for 2017-2021
piplSurveyAll<-read.csv(file = '../Data/dbo_vwAtPiplHeader2021.csv') %>% 
  select_if(all_na) # removes empty columns

#Southern NS beaches for 2014-2016 BRC
pipl2014<-read.csv(file = '../Data/SWNS_2014.csv')
pipl2015<-read.csv(file = '../Data/SWNS_2015.csv')
pipl2016<-read.csv(file = '../Data/SWNS_2016.csv')

# survey data for Northern NS for 2014-2016 BRC
#pipl_NNS<-read.csv(file = '../Data/NNS_ReportCard_rawdata.csv')

#Here I load and clean the productivity data from 2012-2021 surveys
brc1<-read.csv(file = '../Data/Summary of Biological Outcomes 2012-2016.csv') #saved sheet 1 (all years)
brc2<-read.csv(file = '../Data/Productivity_2017-2021_LB_BM.csv') 

#physical data including beach length, area (to be added), and parking lot area (to be added)
beachLength<-read.csv(file = '../Data/beachLength.csv') %>% 
  rename(BeachID = 1, Length_km = 3)
beachArea<-read.csv(file = '../Data/beaches polygon.csv') %>% 
  rename(BeachID = 1, Description = 2) #description typo
extralengths<-read.csv(file = '../Data/supplementary coastlines.csv') %>% 
  rename(BeachID = 1, Length_km = 14) %>% 
  select(1,14)

#Note on beach length excel sheet states those names are the standard and so I'll use them as the name list
beachnames<-beachLength$BeachID

#most complete beachnames list with correct spelling
beachnames<-append(beachnames, c("James", "Bowen Island", "Goose and Burks Point", "Goose Haven", "Taylor Head Bay", "Chance Harbour", "Round Bay", "Roseway", "Hawk Point & The Hawk")) #
#James and Bowen Island are sometimes apart, others are from BRC

#landuse intersection data, read in and select relevant columns (non-forestry related)
landuse<-read.csv(file = '../Data/landuse_intersection.csv') %>% 
  select(1:21,38,54:56,67:70,73) %>% 
  select_if(all_na)%>% 
  rename(Description = descriptio, BeachID = Name)
landuse<-QGIS_names(landuse)

#buffer area (only the intersection of the buffer and NS land area)
buffer_area<-read.csv(file = '../Data/intersection_area.csv') %>% 
  select(Name, Int_Area) %>% 
  rename(land_area = Int_Area, BeachID = Name)
buffer_area<-QGIS_names(buffer_area)

#beachuse is all beach landuse polygons in a 2km buffer (foraging)
beachuse<-read.csv(file = '../Data/beach_intersection.csv') %>% 
  select_if(all_na) %>% 
  select(1:2,58:59,64) %>% 
  rename(BeachID = Name, Description = descriptio, beach_area = union_area)
```

Cleaning and Reformatting
### Survey Data (human impact data)
```{r clean 2017-2021 survey data}
beaches<-piplSurveyAll %>% 
  filter(statprov_code=="NS") %>% 
  select(name) %>% 
  unique() %$% 
  name

#checking to make sure the province codes are correct
x<-piplSurveyAll %>% 
  filter(name %in% beaches) #did this with beachnames first but had 300 less obs.
y<-piplSurveyAll %>% 
  filter(statprov_code == 'NS') 

setdiff(x,y)  #one extra entry in x, use unique id to find form_id 101563 labelled as MB but NS beach

#fixing the mislabelled data point, form_id 101563 labelled as MB
piplSurveyAll[piplSurveyAll$form_id == 101563, 'statprov_code']<-"NS"

#rename columns in survey data so they're easier to work with
goodCols<-c("signs_wetWalker", "signs_dryWalker", "dogs_leashedStart", "dogs_unleashedStart", "dogs_addLeash", "dogs_chaseChicks", "dogs_chaseAdults", "signs_small", "signs_large", "signs_vandalized", "fencedNests", "fencedNests_people", "fencedNests_tracks", "fencedNests_dogTracks", "fencedNests_vandalized", "engagedPeople", "engagedPeople_dogs", "peopleEngaged_dogsTreat", "people_engaged_positive", "vehicles", "vehicles_newTracks", "litter", "peopleTotal", "dogs_leashedTotal", "dogs_unleashedTotal", "dogs_chaseNonPIPL", "kites", "kitesurfers", "kitebuggies", "noSigns_wetWalker", "noSigns_dryWalker", "vehicles_transitTracks", "vehicles_joyrideTracks")
colnames(piplSurveyAll)[54:86]<-goodCols

range(piplSurveyAll$year) #includes observations from 1999-2005 exclude for now

#create a smaller df with only NS beaches with columns I may want data from (survey and weather and ids etc)
piplSurvey<-piplSurveyAll %>%
  select(3,15,16:22,24,27:31,32,34:39,43:50,54:86) %>%
  filter(statprov_code == 'NS') %>% 
  filter(year %in% 2017:2021)

```

Southern NS data has separate sheets with different columns and names, so I'm manually assigning uniform column names by position
```{r clean 2014-2016 survey data}
##Southern
surveyCols<-colnames(piplSurvey)

pipl2014<-pipl2014 %>% 
  select(1,2,4:19,21:33,35:47,62:65) %>% #selects variables in piplSurvey
  separate('Survey.Date..dd.mm.', c('day', 'month'), sep = '/', convert = TRUE) %>% 
  rename(Survey_effort_min = Survey.effort..min., vehicles_and_tracks = sum.veh.and.tracks)
#sync up column names to join all data together
colnames(pipl2014)[c(1:5,7:40,42:49)]<-surveyCols[c(5:10,2,19,18,21:22,24:26,30,27:29,31:59)]

pipl2015<-pipl2015 %>% 
  select(1:3,5:20,26:53,67:70)  %>% 
  rename(Survey_effort_min = Survey.effort..min., vehicles_and_tracks = SUM.veh, fencedNests_dogs = X..of.dogs.inside.symbolic.fencing, peopleEngaged_total = TOT.people.spoken.to)
#sync up column names to join all data together
colnames(pipl2015)[c(1:5,7:32,34:37,39:42,44:51)]<-surveyCols[c(5:9,2,10,19,18,21:22,24:26,30,27:29,31:51,54:55,53,52,56:59)]

pipl2016<-pipl2016 %>% 
  select(1,68:69,3:6,9:15,70,16:19,24:49,64:67) %>% 
  rename(Survey_effort_min = Survey.Effort..min., fencedNests_dogs = Dogs.Inside.Fencing)
#sync up column names to join all data together
colnames(pipl2016)[c(1:5,7:32,34:49)]<-surveyCols[c(5:9,2,10,19,18,21:22,24:26,30,27:29,31:51,54:55,53,52,56:59)]

#reformatting columns present, and column types to bind together
pipl2015<-pipl2015 %>% select(c(-'vehicles_and_tracks', -'peopleEngaged_total', -'fencedNests_dogs'))
pipl2014<-pipl2014 %>% select(c(-'vehicles_and_tracks'))
pipl2016<-pipl2016 %>% select(c(-'fencedNests_dogs'))

pipl2014<-pipl2014 %>% 
  mutate_at(vars(4:5,7:8,11:12), as.character) %>% 
  mutate_at(vars(1:3,6,9:10,13:15,17:18,20:48), as.numeric) %>% 
  mutate_at(vars(16,19), as.logical)

pipl2015<-pipl2015 %>% 
  mutate_at(vars(4:5,7:8,11:12), as.character) %>% 
  mutate_at(vars(1:3,6,9:10,13:15,17:18,20:48), as.numeric) %>% 
  mutate_at(vars(16,19), as.logical)

pipl2016<-pipl2016 %>% 
  mutate_at(vars(4:5,7:8,11:12), as.character) %>% 
  mutate_at(vars(1:3,6,9:10,13:15,17:18,20:48), as.numeric) %>% 
  mutate_at(vars(16,19), as.logical)

x<-bind_rows(pipl2014, pipl2015, pipl2016) %>% 
  select(-'cloud_cover',-'tide_state')

### NNS Sites, missing many columns I'm not sure it's worth including, also vandalized signs is logical not a count

#pipl_NNS<-pipl_NNS %>% select(1:5,8:12,15,17,19,21:24,26)
#colnames(pipl_NNS)[c(1,3:5,18,6:17)]<-surveyCols[c(5,10,38:40,33:35,54:55,31:32,53,46:47,49,51)]
#pipl_NNS<- pipl_NNS %>% select(1:17) %>% rename(Survey_effort_min = effort.min, BeachID = name)

#reformat piplSurvey to match
y<-piplSurvey %>% 
  mutate(across(c(2:4,8:11,17), as.character)) %>% 
  mutate(across(c(5:7,18:22,31:63), as.numeric))
y$New.Nests.Found<-as.logical(ifelse(y$New.Nests.Found == "Yes", TRUE, FALSE))
y$Nest.Chicks.Checked<-as.logical(ifelse(y$Nest.Chicks.Checked == "Yes", TRUE, FALSE))

#one big dataset, needs beachID cleaned
piplSurvey<-bind_rows(x, y) %>% 
  arrange(year) %>% 
  rename(BeachID = name) %>% 
  select(7,1:6,8:64) %>% 
  filter(!is.na(year)) 

#piplSurvey_test<-piplSurvey %>% 
  #mutate(across(c(2:4,7,9:13,15:16,18:46), as.numeric))
```


```{r fixing names for big data}
#plus signs break the code, so manually doing these
piplSurvey[piplSurvey == "Hawk Pt+The Hawk"]<-"Hawk Point & The Hawk"
piplSurvey[piplSurvey == "Roseway+RoundBay"]<-"Round Bay & Roseway"

piplSurvey$BeachID %<>%
  gsub("'", "", .)

#this doesn't match properly in fuzzy join so manually reassigning
piplSurvey[piplSurvey$BeachID == "Silver Sands (Cow Bay)",]<- "Cow Bay"
piplSurvey[piplSurvey$BeachID == "Stoney Beach",]<- "Stoney (Lawrencetown Head)"
piplSurvey[piplSurvey$BeachID == "Lawrencetown Beach",]<- "Stoney (Lawrencetown Head)"

#removing beaches not on the list
WrongBeaches<-c("Maughers Beach", "MacCormacks Beach", "Point Michaud", "Keating Cove", "Purgatory Point")
piplSurvey<-piplSurvey %>% 
  filter(!BeachID %in% WrongBeaches)

#still too many small spelling mistakes, used a fuzzy join (did a test to ensure correct pairs)
x<-as.data.frame(piplSurvey$BeachID) %>% 
  rename(BeachID = 1)
y<-as.data.frame(beachnames) %>% 
  rename(BeachID = 1)

x<-stringdist_join(x, y, 
                by = "BeachID",
                mode = "left",
                ignore_case = FALSE, 
                method = "jw", 
                max_dist = 99, 
                distance_col = "dist") %>%
  group_by(BeachID.x) %>%
  slice_min(order_by = dist, n = 1) %>% 
  unique

colnames(x)<-c("BeachID", "correction", "dist")

piplSurvey<-left_join(piplSurvey, x, by = 'BeachID') %>% 
  rename(BeachID_original = BeachID, BeachID = correction) %>% 
  select(BeachID, year:vehicles_joyrideTracks)

setdiff(piplSurvey$BeachID, beachnames) #all good  
```


### Plover Productivity Data (breeding pairs and productivity)
Here I load and clean the productivity data from 2012-2021 surveys
```{r clean productivity data}

#fix minor issues with brc1
brc1<-brc1 %>% 
  na_if( y = "N/A") %>%  #change manually inputted N/A to NA values
  mutate_at(vars(3:12), as.numeric) %>% #reassign column types to match for joining
  select(1:5,8:11) #remove pairs monitored and site visits columns as brc2 doesn't have these variables


#reformat brc2 to match brc1, remove or rename columns and fill blanks from excel sheet (beach listed once for every 5 entries)
brc2<-brc2 %>% 
  select(1:6,11:12) %>% 
  rename(BeachID = Beach.Name, YE_singles = Singles, YE_pairs = Pairs, Productivity = Yearly.Productivity, Nesting.attempts = n.ofNesting.Attempts, Nestloss_HD = Nestloss) %>% 
  mutate(BeachID = na_if(x = BeachID, y = "")) %>% #change blanks into NA so the fill function can work
  fill(BeachID) %>% #this works because the spreadsheet was ordered by beach name and then year already
  mutate(County = NA)

#fixing BeachID entries to match

#determine which beaches aren't in beachnames (added to the append command in 'load data' chunk)
setdiff(brc2$BeachID, beachnames) #mostly spelling errors, a few places not named in beachnames
setdiff(brc1$BeachID, beachnames) #this list has more beaches not named elsewhere that will be excluded
                               
#using the lists above I manually assigned the correct spelling from the complete list (beachnames)
#these aren't the same as the QGIS misspellings so I did it manually
brc1$BeachID %<>% 
  gsub("Goose Haven, Port Joli", paste(beachnames[64]), .) %>% 
  gsub("Grahams Cove / Ferry Road", paste(beachnames[24]), .) %>%
  gsub("James Beach", paste(beachnames[61]), .) %>%
  gsub("Durham Lane Beach, Port Joli", paste(beachnames[20]), .)
  
brc2$BeachID %<>%
  gsub("\\*", "", .) %>%   
  gsub("&", "and", .) %>% 
  gsub("'", "", .) %>% #removes small formatting differences, punctuation mismatching
  gsub("Cherry Hill", paste(beachnames[9]), .) %>% 
  gsub("Cape LaHave Island", paste(beachnames[6]), .) %>% 
  gsub("Carters and Wobamkek", paste(beachnames[8]), .) %>%
  gsub("Clam Harbour ", paste(beachnames[10]), .) %>% 
  gsub("Conrads", paste(beachnames[12]), .) %>% 
  gsub("Crescent", paste(beachnames[15]), .) %>% 
  gsub("Crows Neck", paste(beachnames[16]), .) %>% 
  gsub("Daniels Head", paste(beachnames[17]), .) %>% 
  gsub("Durham Lane",paste(beachnames[20]), .) %>% 
  gsub("Grahams Cove", paste(beachnames[24]), .) %>%
  gsub("James Beach and Bowen Island", paste(beachnames[30]), .) %>%
  gsub("North East Point", paste(beachnames[39]), .) %>%
  gsub("Rainbow Haven", paste(beachnames[45]), .) %>%
  gsub("Round Bay and Roseway", paste(beachnames[48]), .) %>%
  gsub("Sandhills PP ", paste(beachnames[49]), .) %>%
  gsub("South Harbour ", paste(beachnames[52]), .)

#manually assigning names that aren't working with gsub
#dominion rows 271-275
brc2[271:275, 'BeachID']<-"Dominion (Lingan)"
#pictou rows 241-245
brc2[241:245, 'BeachID']<-"Pictou Bar Spit (Lighthouse)"
# shipping rows 261-265
brc2[261:265, 'BeachID']<-"Shipping Point"

brc1<-brc1 %>% 
  filter(!BeachID %in% c("Margaree Harbour", "MacKay's Point", "Port Mouton Island", "Jimtown", "Linwood", "South Lakevale (Cribbons)", "Tracadie Big Island / Delorey", "Tracadie West Arm", "Ratcliffe Hills (The Cape)"))
#final check should be 0, all beaches should have been added to beach names, removed, or the spelling was fixed
setdiff(brc2$BeachID, beachnames)
setdiff(brc1$BeachID, beachnames)
```


```{r create productivity df}
prodData<-rbind(brc1, brc2) %>% 
  arrange(BeachID, Year) %>% 
  mutate(County = na_if(x = County, y = "")) %>%
  fill(County) #adds County information to data from brc2

#Some sites have County typos (multiple counties attributed to one site)
x<-prodData %>% 
  group_by(BeachID) %>% 
  summarise(count = n_distinct(County)) %>% 
  filter(count>1) %>% 
  select(BeachID) # 21 sites with typos

#choose the county that is written more, most of the typos were just one wrong
y<-prodData %>% 
  count(BeachID, County) %>%
  group_by(BeachID) %>% 
  slice(which.max(n)) %>% 
  select(1:2)

# join the correct county information to the prodData
prodData<-left_join(y, prodData, by = 'BeachID') %>% 
  rename(County = County.x) %>% 
  select(1:2,4:10) #remove old column with typos

#fix empty Productivity
prodData$temp<-prodData$Productivity
prodData$temp<-ifelse(is.na(prodData$Fledglings), NA, ifelse(
   is.na(prodData$temp), 0, prodData$Productivity))
prodData$Productivity<-prodData$temp
prodData$temp<-NULL
```

### Physical Beach Data (Area and Length)
adding beach length (from BRC data) and area (google earth beach polygons)
*will add parking lot size and number information when available*
```{r physical beach data clean}
beachLength
prodData<-left_join(prodData, beachLength, by = 'BeachID')

prodData %>% 
  group_by(BeachID) %>% 
  summarize(nas = sum(is.na(Length_km))) %>% 
  filter(nas > 0) #6 beaches in the productivity sheet without beach length calculated

#reformat and join the extra coastline lengths (done by Allegra) to the beachLength df
extralengths$Region<-ifelse(extralengths$BeachID %in% c("Chance Harbour", "James", "Bowen Island"), "nNS", "sNS")

beachLength<-rbind(beachLength, extralengths)

#reformat and join the beach area data to beach length
beachArea<-beachArea %>% 
  select('BeachID', 'Description', 'BeachArea') %>% 
  filter(!BeachID == 'White Point Beach') #this is in the polygons as gull island, same beach

beachArea<-QGIS_names(beachArea)

beachPhys<-left_join(beachLength, beachArea, by = 'BeachID') %>% 
  filter(!BeachID == 'Gull Island Beach')

beachPhys %>% 
  filter(is.na(BeachArea)) # Only 1 NA foxbar, it's included within roundbay's polygon

#creating a column for what manages the beach
beachPhys$Management<-sub(".*Ownership: ", "", beachPhys$Description)
beachPhys$Management<-ifelse(grepl("Digitized|Beach Name|digitized", beachPhys$Management), NA, beachPhys$Management)

#manually filling in missing values

##Ogdens pond and Harbour breeze not entirely sure yet
##Still missing Green Bay and Durham Lane
beachPhys$Management<-ifelse(beachPhys$BeachID %in% c("Burks Point", "Chance Harbour", "Fox Bar", "Goose Haven", "Harbour Breeze, Port Joli", "Middle Harbour", "Ogdens Pond", "Roaring Bull Point", "White Point Beach"), "Private", beachPhys$Management)
beachPhys$Management<-ifelse(beachPhys$BeachID %in% c("Inverness Beach", "Cow Bay"), "Municipal", beachPhys$Management)
beachPhys$Management<-ifelse(beachPhys$BeachID %in% c("Taylor Head Bay", "Hirtles"), "Provincial", beachPhys$Management) #hirtles is also managed municipally
```


```{r landuse processing}
#creating a new variable with the landuse assignments
landuse<-landuse %>% 
  mutate(landclass = ifelse(landuse$FORNON == 87, "Urban", ifelse(
    landuse$FORNON == 86, "Agriculture", ifelse(
    landuse$FORNON == 94, "Beach", "Road"))))

#fixing beachuse, qgis union created two sets of columns I need to fill one and keep it
beachuse[beachuse == ""] <- NA

beachuse$BeachID<-ifelse(is.na(beachuse$BeachID), beachuse$Name_2, beachuse$BeachID)
beachuse$Description<-ifelse(is.na(beachuse$Description), beachuse$Name_2, beachuse$Description)

beachuse<-beachuse %>% 
  select(1,2,5)
beachuse<-QGIS_names(beachuse) #fixing misspellings from QGIS data

#summarize the area within the buffer by landclass designation
x<-landuse %>% 
  group_by(BeachID,landclass) %>% 
  summarize(tot_area = sum(Int_Area), tot_area_km = tot_area/1000000) #currently 30km buffer region data
x<-left_join(x,buffer_area) %>% 
  mutate(percentage = tot_area/land_area)

y<-beachuse %>% 
  group_by(BeachID) %>% 
  summarize(tot_area_beach = sum(beach_area), tot_area_beach_km = tot_area_beach/1000000) # currently 2km buffer

x<-x %>% 
  mutate(temp = paste(BeachID, landclass, sep = "_"))
y<-y %>% 
  mutate(temp = paste(BeachID, "_Beach", sep =""))

x<-full_join(x,y, by = c('temp', 'BeachID'))
x$tot_area<-ifelse(x$landclass =='Beach', x$tot_area_beach, x$tot_area)
x$tot_area_km<-ifelse(x$landclass =='Beach', x$tot_area_beach_km, x$tot_area_km)  
x$percentage<-ifelse(x$landclass =='Beach', NA, x$percentage)

#join x to BeachPhys, but remove last row adn last 3 columns
beachPhys<-full_join(beachPhys, x[,1:6], by = 'BeachID')

# fix goose haven naming, replace region and length with Port Joli (Goose Haven) values and then remove
beachPhys$Region[beachPhys$BeachID == "Goose Haven"]<- "sNS"
beachPhys$Length_km[beachPhys$BeachID == "Goose Haven"]<-0.477
beachPhys<- beachPhys %>% 
  filter(!BeachID == "Port Joli (Goose Haven)")
```


## End

just removing extra dfs that aren't clean or needed
```{r cleanup, eval = FALSE}
x<-NULL
y<-NULL
brc1<-NULL
brc2<-NULL
beachArea<-NULL
beachLength<-NULL
extralengths<-NULL
landuse<-NULL
piplSurveyAll<-NULL
beachuse<-NULL
pipl2014<-NULL
pipl2015<-NULL
pipl2016<-NULL
buffer_area<-NULL
```

## End